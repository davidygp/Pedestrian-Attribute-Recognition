{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/usr/lib/python36.zip',\n",
       " '/usr/lib/python3.6',\n",
       " '/usr/lib/python3.6/lib-dynload',\n",
       " '',\n",
       " '/usr/local/lib/python3.6/dist-packages',\n",
       " '/usr/lib/python3/dist-packages',\n",
       " '/usr/local/lib/python3.6/dist-packages/IPython/extensions',\n",
       " '/home/svu/e0384946/.ipython']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"/home/svu/e0384946/anaconda3/lib/python3.7/site-packages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving into Pedestrian-Attribute-Recognition folder\n",
      "/home/svu/e0384946/Pedestrian-Attribute-Recognition\n"
     ]
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "if \"Pedestrian-Attribute-Recognition\" in cwd:\n",
    "    print(\"We're currently in Pedestrian-Attribute-Recognition folder\")\n",
    "else:\n",
    "    print(\"Moving into Pedestrian-Attribute-Recognition folder\")\n",
    "    %cd Pedestrian-Attribute-Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/svu/e0384946/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/svu/e0384946/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/svu/e0384946/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/svu/e0384946/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/svu/e0384946/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/svu/e0384946/anaconda3/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "from collections import OrderedDict, defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from batch_engine import valid_trainer, batch_trainer\n",
    "from config import argument_parser\n",
    "from dataset.AttrDataset import AttrDataset, get_transform, AttrDataset_new, parse_transformation_dict\n",
    "from loss.CE_loss import CEL_Sigmoid\n",
    "from models.base_block import FeatClassifier, BaseClassifier\n",
    "from models.resnet import resnet50\n",
    "from tools.function import get_model_log_path, get_pedestrian_metrics\n",
    "from tools.utils import time_str, save_ckpt, ReDirectSTD, set_seed\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import getpass\n",
    "import inspect\n",
    "\n",
    "set_seed(605)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = SummaryWriter('runs/exp-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainer(epoch, model, train_loader, valid_loader, criterion, optimizer, lr_scheduler,\n",
    "            path, measure):\n",
    "    maximum = float(-np.inf)\n",
    "    best_epoch = 0\n",
    "\n",
    "    result_list = defaultdict()\n",
    "\n",
    "    for i in range(epoch):\n",
    "\n",
    "        train_loss, train_gt, train_probs = batch_trainer(\n",
    "            epoch=i,\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "        )\n",
    "\n",
    "        valid_loss, valid_gt, valid_probs = valid_trainer(\n",
    "            model=model,\n",
    "            valid_loader=valid_loader,\n",
    "            criterion=criterion,\n",
    "        )\n",
    "\n",
    "        lr_scheduler.step(metrics=valid_loss, epoch=i)\n",
    "\n",
    "        train_result = get_pedestrian_metrics(train_gt, train_probs)\n",
    "        valid_result = get_pedestrian_metrics(valid_gt, valid_probs)\n",
    "\n",
    "        # tensorboard added\n",
    "        # writer.add_scalar(tag, function, iteration)\n",
    "        writer_step = i\n",
    "\n",
    "        writer.add_scalar('Train Loss', train_loss, writer_step)\n",
    "\n",
    "        writer.add_scalar('Train Accuracy', train_result.instance_acc, writer_step)\n",
    "        writer.add_scalar('Train Precision', train_result.instance_prec, writer_step)\n",
    "        writer.add_scalar('Train Recall', train_result.instance_recall, writer_step)\n",
    "        writer.add_scalar('Train F1', train_result.instance_f1, writer_step)\n",
    "\n",
    "        writer.add_scalar('Train Mean Accuracy', train_result.ma, writer_step)\n",
    "        writer.add_scalar('Train Pos Recall', np.mean(train_result.label_pos_recall), writer_step)\n",
    "        writer.add_scalar('Train Neg Recall', np.mean(train_result.label_neg_recall), writer_step)\n",
    "\n",
    "\n",
    "        writer.add_scalar('Valid Loss', valid_loss, writer_step)\n",
    "\n",
    "        writer.add_scalar('Valid Accuracy', valid_result.instance_acc, writer_step)\n",
    "        writer.add_scalar('Valid Precision', valid_result.instance_prec, writer_step)\n",
    "        writer.add_scalar('Valid Recall', valid_result.instance_recall, writer_step)\n",
    "        writer.add_scalar('Valid F1', valid_result.instance_f1, writer_step)\n",
    "\n",
    "        writer.add_scalar('Valid Mean Accuracy', valid_result.ma, writer_step)\n",
    "        writer.add_scalar('Valid Pos Recall', np.mean(valid_result.label_pos_recall), writer_step)\n",
    "        writer.add_scalar('Valid Neg Recall', np.mean(valid_result.label_neg_recall), writer_step)\n",
    "\n",
    "        print(f'Evaluation on test set, \\n',\n",
    "              'ma: {:.4f},  pos_recall: {:.4f} , neg_recall: {:.4f} \\n'.format(\n",
    "                  valid_result.ma, np.mean(valid_result.label_pos_recall), np.mean(valid_result.label_neg_recall)),\n",
    "              'Acc: {:.4f}, Prec: {:.4f}, Rec: {:.4f}, F1: {:.4f}'.format(\n",
    "                  valid_result.instance_acc, valid_result.instance_prec, valid_result.instance_recall,\n",
    "                  valid_result.instance_f1))\n",
    "\n",
    "        print(f'{time_str()}')\n",
    "        print('-' * 60)\n",
    "\n",
    "        # We only allow \"accuracy\" or \"f1\"\n",
    "        assert((measure.lower()==\"accuracy\") or (measure.lower()==\"f1\"))\n",
    "        if measure == 'accuracy':\n",
    "            cur_metric = valid_result.ma\n",
    "        elif measure == 'f1':\n",
    "            cur_metric = valid_result.instance_f1\n",
    "\n",
    "        if cur_metric > maximum:\n",
    "            maximum = cur_metric\n",
    "            best_epoch = i\n",
    "            save_ckpt(model, path, i, maximum)\n",
    "\n",
    "        result_list[i] = [train_result, valid_result]\n",
    "\n",
    "    writer.close()\n",
    "\n",
    "    torch.save(result_list, os.path.join(os.path.dirname(path), 'metric_log.pkl'))\n",
    "\n",
    "    return maximum, best_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class args_config():\n",
    "    def __init__(self):\n",
    "        self.dataset=\"RAP\"\n",
    "        self.debug='store_false'\n",
    "        self.batchsize=64\n",
    "        self.train_epoch=30\n",
    "        self.height=256\n",
    "        self.width=192\n",
    "        self.lr_ft=0.01\n",
    "        self.lr_new=0.1\n",
    "        self.classifier='base'\n",
    "        self.momentum=0.9\n",
    "        self.weight_decay=5e-4\n",
    "        self.train_split=\"trainval\" #choices=['train' 'trainval']\n",
    "        self.valid_split=\"test\" #choices=['test' 'valid']\n",
    "        self.device=0\n",
    "        self.redirector='store_false'\n",
    "        self.use_bn='store_false'\n",
    "        self.train_transform={\"Order\":[\"Resize\", \"Pad\", \"RandomErase\", \"RandomCrop\", \"RandomAffine\",\\\n",
    "                                       \"RandomHorizontalFlip\", \"ToTensor\", \"Normalize\", \"Mosiac\"],\n",
    "                              \"Resize\":{\"size\":(self.height,self.width)},\n",
    "                              \"Pad\":{\"padding\":10},\n",
    "                              \"RandomCrop\":{\"size\":(self.height,self.width)},\n",
    "                              \"RandomAffine\":{\"degrees\":(-5,5), \"translate\":(0.05,0.05), \"scale\":(0.99,1.01), \"shear\":(-5,5)},\n",
    "                              \"RandomHorizontalFlip\":{},\n",
    "                              \"RandomErase\":{\"Wr\":(0.05, 0.3), \"Hr\":(0.05, 0.3)},\n",
    "                              \"Mosaic\":{\"Wj\":0.2, \"Hj\":0.2, \"Prob\":0.05},\n",
    "                              \"Normalize\":{\"mean\":[0.485, 0.456, 0.406], \"std\":[0.229, 0.224, 0.225]}\n",
    "                             }\n",
    "        self.valid_transform={\"Order\":[\"Resize\", \"ToTensor\", \"Normalize\"],\n",
    "                              \"Resize\":{\"size\":(self.height,self.width)},\n",
    "                              \"Normalize\":{\"mean\":[0.485, 0.456, 0.406], \"std\":[0.229, 0.224, 0.225]}\n",
    "                             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = args_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.dataset = \"PA100k\"\n",
    "args.dataset = \"PETA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "redirector stdout\n",
      "OrderedDict([('dataset', 'PETA'),\n",
      "             ('debug', 'store_false'),\n",
      "             ('batchsize', 64),\n",
      "             ('train_epoch', 30),\n",
      "             ('height', 256),\n",
      "             ('width', 192),\n",
      "             ('lr_ft', 0.01),\n",
      "             ('lr_new', 0.1),\n",
      "             ('classifier', 'base'),\n",
      "             ('momentum', 0.9),\n",
      "             ('weight_decay', 0.0005),\n",
      "             ('train_split', 'trainval'),\n",
      "             ('valid_split', 'test'),\n",
      "             ('device', 0),\n",
      "             ('redirector', 'store_false'),\n",
      "             ('use_bn', 'store_false'),\n",
      "             ('train_transform',\n",
      "              {'Mosaic': {'Hj': 0.2, 'Prob': 0.05, 'Wj': 0.2},\n",
      "               'Normalize': {'mean': [0.485, 0.456, 0.406],\n",
      "                             'std': [0.229, 0.224, 0.225]},\n",
      "               'Order': ['Resize',\n",
      "                         'Pad',\n",
      "                         'RandomErase',\n",
      "                         'RandomCrop',\n",
      "                         'RandomAffine',\n",
      "                         'RandomHorizontalFlip',\n",
      "                         'ToTensor',\n",
      "                         'Normalize',\n",
      "                         'Mosiac'],\n",
      "               'Pad': {'padding': 10},\n",
      "               'RandomAffine': {'degrees': (-5, 5),\n",
      "                                'scale': (0.99, 1.01),\n",
      "                                'shear': (-5, 5),\n",
      "                                'translate': (0.05, 0.05)},\n",
      "               'RandomCrop': {'size': (256, 192)},\n",
      "               'RandomErase': {'Hr': (0.05, 0.3), 'Wr': (0.05, 0.3)},\n",
      "               'RandomHorizontalFlip': {},\n",
      "               'Resize': {'size': (256, 192)}}),\n",
      "             ('valid_transform',\n",
      "              {'Normalize': {'mean': [0.485, 0.456, 0.406],\n",
      "                             'std': [0.229, 0.224, 0.225]},\n",
      "               'Order': ['Resize', 'ToTensor', 'Normalize'],\n",
      "               'Resize': {'size': (256, 192)}})])\n",
      "------------------------------------------------------------\n",
      "use GPU0 for training\n",
      "train set: PETA trainval, test set: test\n",
      "Compose(\n",
      "    Resize(size=(256, 192), interpolation=PIL.Image.BILINEAR)\n",
      "    Pad(padding=10, fill=0, padding_mode=constant)\n",
      "    <dataset.AttrDataset.RandomErase object at 0x2ada10c63d68>\n",
      "    RandomCrop(size=(256, 192), padding=None)\n",
      "    RandomAffine(degrees=(-5, 5), translate=(0.05, 0.05), scale=(0.99, 1.01), shear=[-5, 5, 0.0, 0.0])\n",
      "    RandomHorizontalFlip(p=0.5)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "Compose(\n",
      "    Resize(size=(256, 192), interpolation=PIL.Image.BILINEAR)\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
      ")\n",
      "trainval set: 11400, test set: 7600, attr_num : 116\n",
      "2020-06-26_07-28-51, Step 19/179 in Ep 0, 0.21s  train_loss:71.8010\n",
      "2020-06-26_07-28-56, Step 39/179 in Ep 0, 0.21s  train_loss:49.4239\n",
      "2020-06-26_07-29-00, Step 59/179 in Ep 0, 0.22s  train_loss:42.0124\n",
      "2020-06-26_07-29-04, Step 79/179 in Ep 0, 0.21s  train_loss:40.0837\n",
      "2020-06-26_07-29-08, Step 99/179 in Ep 0, 0.21s  train_loss:35.7277\n",
      "2020-06-26_07-29-12, Step 119/179 in Ep 0, 0.21s  train_loss:35.0721\n",
      "2020-06-26_07-29-16, Step 139/179 in Ep 0, 0.22s  train_loss:33.7143\n",
      "2020-06-26_07-29-21, Step 159/179 in Ep 0, 0.21s  train_loss:32.6389\n",
      "2020-06-26_07-29-24, Step 178/179 in Ep 0, 0.06s  train_loss:33.0346\n",
      "Epoch 0, LR 0.1, Train_Time 38.07s, Loss: 45.8156\n",
      "Evaluation on test set, \n",
      " ma: 0.6809,  pos_recall: 0.4223 , neg_recall: 0.9396 \n",
      " Acc: 0.5931, Prec: 0.7385, Rec: 0.7266, F1: 0.7283\n",
      "2020-06-26_07-29-37\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-29-43, Step 19/179 in Ep 1, 0.21s  train_loss:30.1595\n",
      "2020-06-26_07-29-47, Step 39/179 in Ep 1, 0.21s  train_loss:28.2706\n",
      "2020-06-26_07-29-51, Step 59/179 in Ep 1, 0.21s  train_loss:30.1222\n",
      "2020-06-26_07-29-56, Step 79/179 in Ep 1, 0.21s  train_loss:32.5159\n",
      "2020-06-26_07-30-00, Step 99/179 in Ep 1, 0.21s  train_loss:28.2233\n",
      "2020-06-26_07-30-04, Step 119/179 in Ep 1, 0.21s  train_loss:27.7699\n",
      "2020-06-26_07-30-08, Step 139/179 in Ep 1, 0.21s  train_loss:31.8730\n",
      "2020-06-26_07-30-12, Step 159/179 in Ep 1, 0.21s  train_loss:32.4483\n",
      "2020-06-26_07-30-16, Step 178/179 in Ep 1, 0.05s  train_loss:34.6637\n",
      "Epoch 1, LR 0.1, Train_Time 37.96s, Loss: 29.9558\n",
      "Evaluation on test set, \n",
      " ma: 0.7180,  pos_recall: 0.4845 , neg_recall: 0.9516 \n",
      " Acc: 0.6714, Prec: 0.7945, Rec: 0.7825, F1: 0.7857\n",
      "2020-06-26_07-30-24\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-30-31, Step 19/179 in Ep 2, 0.21s  train_loss:26.9974\n",
      "2020-06-26_07-30-35, Step 39/179 in Ep 2, 0.21s  train_loss:26.3267\n",
      "2020-06-26_07-30-39, Step 59/179 in Ep 2, 0.21s  train_loss:23.5467\n",
      "2020-06-26_07-30-43, Step 79/179 in Ep 2, 0.22s  train_loss:29.6061\n",
      "2020-06-26_07-30-47, Step 99/179 in Ep 2, 0.21s  train_loss:26.8091\n",
      "2020-06-26_07-30-52, Step 119/179 in Ep 2, 0.21s  train_loss:24.1333\n",
      "2020-06-26_07-30-56, Step 139/179 in Ep 2, 0.21s  train_loss:24.8648\n",
      "2020-06-26_07-31-00, Step 159/179 in Ep 2, 0.21s  train_loss:22.2251\n",
      "2020-06-26_07-31-04, Step 178/179 in Ep 2, 0.05s  train_loss:36.5860\n",
      "Epoch 2, LR 0.1, Train_Time 38.20s, Loss: 26.2154\n",
      "Evaluation on test set, \n",
      " ma: 0.7350,  pos_recall: 0.5189 , neg_recall: 0.9511 \n",
      " Acc: 0.6947, Prec: 0.8022, Rec: 0.8058, F1: 0.8015\n",
      "2020-06-26_07-31-12\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-31-18, Step 19/179 in Ep 3, 0.21s  train_loss:29.5865\n",
      "2020-06-26_07-31-22, Step 39/179 in Ep 3, 0.21s  train_loss:24.9585\n",
      "2020-06-26_07-31-27, Step 59/179 in Ep 3, 0.21s  train_loss:25.6344\n",
      "2020-06-26_07-31-31, Step 79/179 in Ep 3, 0.21s  train_loss:24.6521\n",
      "2020-06-26_07-31-35, Step 99/179 in Ep 3, 0.21s  train_loss:25.8606\n",
      "2020-06-26_07-31-39, Step 119/179 in Ep 3, 0.21s  train_loss:24.3053\n",
      "2020-06-26_07-31-44, Step 139/179 in Ep 3, 0.21s  train_loss:22.8705\n",
      "2020-06-26_07-31-48, Step 159/179 in Ep 3, 0.21s  train_loss:27.3479\n",
      "2020-06-26_07-31-51, Step 178/179 in Ep 3, 0.05s  train_loss:40.1251\n",
      "Epoch 3, LR 0.1, Train_Time 37.89s, Loss: 24.0667\n",
      "Evaluation on test set, \n",
      " ma: 0.7515,  pos_recall: 0.5551 , neg_recall: 0.9478 \n",
      " Acc: 0.6928, Prec: 0.7879, Rec: 0.8173, F1: 0.7996\n",
      "2020-06-26_07-31-59\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-32-04, Step 19/179 in Ep 4, 0.21s  train_loss:20.6645\n",
      "2020-06-26_07-32-08, Step 39/179 in Ep 4, 0.21s  train_loss:21.0896\n",
      "2020-06-26_07-32-12, Step 59/179 in Ep 4, 0.21s  train_loss:21.0621\n",
      "2020-06-26_07-32-17, Step 79/179 in Ep 4, 0.21s  train_loss:21.4383\n",
      "2020-06-26_07-32-21, Step 99/179 in Ep 4, 0.21s  train_loss:18.3691\n",
      "2020-06-26_07-32-25, Step 119/179 in Ep 4, 0.21s  train_loss:22.0172\n",
      "2020-06-26_07-32-29, Step 139/179 in Ep 4, 0.21s  train_loss:21.1439\n",
      "2020-06-26_07-32-33, Step 159/179 in Ep 4, 0.21s  train_loss:24.1624\n",
      "2020-06-26_07-32-37, Step 178/179 in Ep 4, 0.06s  train_loss:25.7687\n",
      "Epoch 4, LR 0.1, Train_Time 37.82s, Loss: 22.2115\n",
      "Evaluation on test set, \n",
      " ma: 0.7536,  pos_recall: 0.5506 , neg_recall: 0.9567 \n",
      " Acc: 0.6806, Prec: 0.7975, Rec: 0.7861, F1: 0.7890\n",
      "2020-06-26_07-32-45\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-32-50, Step 19/179 in Ep 5, 0.21s  train_loss:20.1591\n",
      "2020-06-26_07-32-54, Step 39/179 in Ep 5, 0.21s  train_loss:22.0143\n",
      "2020-06-26_07-32-58, Step 59/179 in Ep 5, 0.21s  train_loss:20.7716\n",
      "2020-06-26_07-33-03, Step 79/179 in Ep 5, 0.21s  train_loss:21.8935\n",
      "2020-06-26_07-33-07, Step 99/179 in Ep 5, 0.21s  train_loss:20.0583\n",
      "2020-06-26_07-33-11, Step 119/179 in Ep 5, 0.21s  train_loss:21.5780\n",
      "2020-06-26_07-33-15, Step 139/179 in Ep 5, 0.21s  train_loss:19.3803\n",
      "2020-06-26_07-33-19, Step 159/179 in Ep 5, 0.21s  train_loss:21.5689\n",
      "2020-06-26_07-33-23, Step 178/179 in Ep 5, 0.05s  train_loss:28.6453\n",
      "Epoch 5, LR 0.1, Train_Time 37.93s, Loss: 20.8013\n",
      "Evaluation on test set, \n",
      " ma: 0.7641,  pos_recall: 0.5685 , neg_recall: 0.9598 \n",
      " Acc: 0.7230, Prec: 0.8239, Rec: 0.8188, F1: 0.8192\n",
      "2020-06-26_07-33-31\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-33-37, Step 19/179 in Ep 6, 0.21s  train_loss:16.4795\n",
      "2020-06-26_07-33-42, Step 39/179 in Ep 6, 0.21s  train_loss:19.3199\n",
      "2020-06-26_07-33-46, Step 59/179 in Ep 6, 0.22s  train_loss:18.8449\n",
      "2020-06-26_07-33-50, Step 79/179 in Ep 6, 0.21s  train_loss:20.4660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-26_07-33-54, Step 99/179 in Ep 6, 0.21s  train_loss:20.0282\n",
      "2020-06-26_07-33-58, Step 119/179 in Ep 6, 0.21s  train_loss:19.3027\n",
      "2020-06-26_07-34-03, Step 139/179 in Ep 6, 0.21s  train_loss:22.1589\n",
      "2020-06-26_07-34-07, Step 159/179 in Ep 6, 0.21s  train_loss:20.3984\n",
      "2020-06-26_07-34-11, Step 178/179 in Ep 6, 0.06s  train_loss:30.0129\n",
      "Epoch 6, LR 0.1, Train_Time 38.14s, Loss: 19.8216\n",
      "Evaluation on test set, \n",
      " ma: 0.7751,  pos_recall: 0.5917 , neg_recall: 0.9586 \n",
      " Acc: 0.7363, Prec: 0.8298, Rec: 0.8340, F1: 0.8298\n",
      "2020-06-26_07-34-19\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-34-25, Step 19/179 in Ep 7, 0.21s  train_loss:18.0113\n",
      "2020-06-26_07-34-29, Step 39/179 in Ep 7, 0.21s  train_loss:15.1647\n",
      "2020-06-26_07-34-34, Step 59/179 in Ep 7, 0.21s  train_loss:17.4299\n",
      "2020-06-26_07-34-38, Step 79/179 in Ep 7, 0.21s  train_loss:18.7968\n",
      "2020-06-26_07-34-42, Step 99/179 in Ep 7, 0.21s  train_loss:18.7372\n",
      "2020-06-26_07-34-46, Step 119/179 in Ep 7, 0.21s  train_loss:18.6375\n",
      "2020-06-26_07-34-50, Step 139/179 in Ep 7, 0.21s  train_loss:18.4183\n",
      "2020-06-26_07-34-55, Step 159/179 in Ep 7, 0.21s  train_loss:17.2347\n",
      "2020-06-26_07-34-58, Step 178/179 in Ep 7, 0.06s  train_loss:28.1024\n",
      "Epoch 7, LR 0.1, Train_Time 37.90s, Loss: 18.8012\n",
      "Evaluation on test set, \n",
      " ma: 0.7649,  pos_recall: 0.5690 , neg_recall: 0.9608 \n",
      " Acc: 0.7398, Prec: 0.8418, Rec: 0.8266, F1: 0.8320\n",
      "2020-06-26_07-35-06\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-35-13, Step 19/179 in Ep 8, 0.21s  train_loss:15.0576\n",
      "2020-06-26_07-35-17, Step 39/179 in Ep 8, 0.21s  train_loss:13.9985\n",
      "2020-06-26_07-35-21, Step 59/179 in Ep 8, 0.21s  train_loss:18.5690\n",
      "2020-06-26_07-35-25, Step 79/179 in Ep 8, 0.21s  train_loss:15.8525\n",
      "2020-06-26_07-35-29, Step 99/179 in Ep 8, 0.21s  train_loss:16.6099\n",
      "2020-06-26_07-35-34, Step 119/179 in Ep 8, 0.21s  train_loss:14.9945\n",
      "2020-06-26_07-35-38, Step 139/179 in Ep 8, 0.21s  train_loss:20.6681\n",
      "2020-06-26_07-35-42, Step 159/179 in Ep 8, 0.21s  train_loss:17.9879\n",
      "2020-06-26_07-35-46, Step 178/179 in Ep 8, 0.06s  train_loss:29.4317\n",
      "Epoch 8, LR 0.1, Train_Time 37.91s, Loss: 17.7910\n",
      "Evaluation on test set, \n",
      " ma: 0.7790,  pos_recall: 0.5938 , neg_recall: 0.9643 \n",
      " Acc: 0.7466, Prec: 0.8399, Rec: 0.8344, F1: 0.8354\n",
      "2020-06-26_07-35-54\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-36-00, Step 19/179 in Ep 9, 0.21s  train_loss:17.1039\n",
      "2020-06-26_07-36-04, Step 39/179 in Ep 9, 0.21s  train_loss:14.0060\n",
      "2020-06-26_07-36-08, Step 59/179 in Ep 9, 0.22s  train_loss:15.1544\n",
      "2020-06-26_07-36-13, Step 79/179 in Ep 9, 0.21s  train_loss:17.8388\n",
      "2020-06-26_07-36-17, Step 99/179 in Ep 9, 0.21s  train_loss:13.9819\n",
      "2020-06-26_07-36-21, Step 119/179 in Ep 9, 0.21s  train_loss:14.0535\n",
      "2020-06-26_07-36-25, Step 139/179 in Ep 9, 0.21s  train_loss:18.5822\n",
      "2020-06-26_07-36-30, Step 159/179 in Ep 9, 0.21s  train_loss:17.7799\n",
      "2020-06-26_07-36-33, Step 178/179 in Ep 9, 0.05s  train_loss:37.2056\n",
      "Epoch 9, LR 0.1, Train_Time 38.08s, Loss: 16.9911\n",
      "Evaluation on test set, \n",
      " ma: 0.7787,  pos_recall: 0.5971 , neg_recall: 0.9603 \n",
      " Acc: 0.7478, Prec: 0.8345, Rec: 0.8426, F1: 0.8367\n",
      "2020-06-26_07-36-41\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-36-48, Step 19/179 in Ep 10, 0.21s  train_loss:14.7529\n",
      "2020-06-26_07-36-52, Step 39/179 in Ep 10, 0.21s  train_loss:14.6309\n",
      "2020-06-26_07-36-56, Step 59/179 in Ep 10, 0.21s  train_loss:13.1926\n",
      "2020-06-26_07-37-00, Step 79/179 in Ep 10, 0.21s  train_loss:17.1937\n",
      "2020-06-26_07-37-04, Step 99/179 in Ep 10, 0.21s  train_loss:14.0734\n",
      "2020-06-26_07-37-09, Step 119/179 in Ep 10, 0.22s  train_loss:15.2006\n",
      "2020-06-26_07-37-13, Step 139/179 in Ep 10, 0.21s  train_loss:18.0381\n",
      "2020-06-26_07-37-17, Step 159/179 in Ep 10, 0.21s  train_loss:16.1217\n",
      "2020-06-26_07-37-21, Step 178/179 in Ep 10, 0.06s  train_loss:38.6254\n",
      "Epoch 10, LR 0.1, Train_Time 38.00s, Loss: 16.2904\n",
      "Evaluation on test set, \n",
      " ma: 0.7835,  pos_recall: 0.6044 , neg_recall: 0.9625 \n",
      " Acc: 0.7430, Prec: 0.8353, Rec: 0.8351, F1: 0.8332\n",
      "2020-06-26_07-37-29\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-37-34, Step 19/179 in Ep 11, 0.21s  train_loss:13.6201\n",
      "2020-06-26_07-37-38, Step 39/179 in Ep 11, 0.21s  train_loss:14.7827\n",
      "2020-06-26_07-37-42, Step 59/179 in Ep 11, 0.21s  train_loss:15.8750\n",
      "2020-06-26_07-37-46, Step 79/179 in Ep 11, 0.21s  train_loss:16.6170\n",
      "2020-06-26_07-37-50, Step 99/179 in Ep 11, 0.21s  train_loss:17.5449\n",
      "2020-06-26_07-37-55, Step 119/179 in Ep 11, 0.21s  train_loss:13.9962\n",
      "2020-06-26_07-37-59, Step 139/179 in Ep 11, 0.21s  train_loss:14.7251\n",
      "2020-06-26_07-38-03, Step 159/179 in Ep 11, 0.21s  train_loss:15.4000\n",
      "2020-06-26_07-38-07, Step 178/179 in Ep 11, 0.05s  train_loss:23.6637\n",
      "Epoch 11, LR 0.1, Train_Time 38.07s, Loss: 15.5166\n",
      "Evaluation on test set, \n",
      " ma: 0.7887,  pos_recall: 0.6156 , neg_recall: 0.9618 \n",
      " Acc: 0.7502, Prec: 0.8390, Rec: 0.8413, F1: 0.8384\n",
      "2020-06-26_07-38-15\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-38-21, Step 19/179 in Ep 12, 0.21s  train_loss:15.5508\n",
      "2020-06-26_07-38-25, Step 39/179 in Ep 12, 0.21s  train_loss:14.4473\n",
      "2020-06-26_07-38-30, Step 59/179 in Ep 12, 0.21s  train_loss:17.0899\n",
      "2020-06-26_07-38-34, Step 79/179 in Ep 12, 0.21s  train_loss:14.9081\n",
      "2020-06-26_07-38-38, Step 99/179 in Ep 12, 0.21s  train_loss:13.5698\n",
      "2020-06-26_07-38-42, Step 119/179 in Ep 12, 0.21s  train_loss:13.4424\n",
      "2020-06-26_07-38-46, Step 139/179 in Ep 12, 0.21s  train_loss:14.5258\n",
      "2020-06-26_07-38-50, Step 159/179 in Ep 12, 0.21s  train_loss:14.0782\n",
      "2020-06-26_07-38-54, Step 178/179 in Ep 12, 0.05s  train_loss:35.4287\n",
      "Epoch 12, LR 0.1, Train_Time 37.94s, Loss: 14.8762\n",
      "Evaluation on test set, \n",
      " ma: 0.7819,  pos_recall: 0.5987 , neg_recall: 0.9651 \n",
      " Acc: 0.7562, Prec: 0.8472, Rec: 0.8419, F1: 0.8428\n",
      "2020-06-26_07-39-02\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-39-08, Step 19/179 in Ep 13, 0.21s  train_loss:13.7415\n",
      "2020-06-26_07-39-13, Step 39/179 in Ep 13, 0.21s  train_loss:12.4297\n",
      "2020-06-26_07-39-17, Step 59/179 in Ep 13, 0.21s  train_loss:13.9719\n",
      "2020-06-26_07-39-21, Step 79/179 in Ep 13, 0.21s  train_loss:16.9518\n",
      "2020-06-26_07-39-25, Step 99/179 in Ep 13, 0.21s  train_loss:14.0518\n",
      "2020-06-26_07-39-29, Step 119/179 in Ep 13, 0.21s  train_loss:12.3697\n",
      "2020-06-26_07-39-34, Step 139/179 in Ep 13, 0.21s  train_loss:13.4584\n",
      "2020-06-26_07-39-38, Step 159/179 in Ep 13, 0.21s  train_loss:15.3377\n",
      "2020-06-26_07-39-42, Step 178/179 in Ep 13, 0.06s  train_loss:40.4636\n",
      "Epoch 13, LR 0.1, Train_Time 37.92s, Loss: 14.3112\n",
      "Evaluation on test set, \n",
      " ma: 0.7797,  pos_recall: 0.5949 , neg_recall: 0.9645 \n",
      " Acc: 0.7593, Prec: 0.8510, Rec: 0.8427, F1: 0.8451\n",
      "2020-06-26_07-39-50\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-39-56, Step 19/179 in Ep 14, 0.21s  train_loss:13.1356\n",
      "2020-06-26_07-40-00, Step 39/179 in Ep 14, 0.22s  train_loss:11.3209\n",
      "2020-06-26_07-40-04, Step 59/179 in Ep 14, 0.21s  train_loss:9.6203\n",
      "2020-06-26_07-40-09, Step 79/179 in Ep 14, 0.21s  train_loss:11.8628\n",
      "2020-06-26_07-40-13, Step 99/179 in Ep 14, 0.21s  train_loss:10.7882\n",
      "2020-06-26_07-40-17, Step 119/179 in Ep 14, 0.21s  train_loss:9.0522\n",
      "2020-06-26_07-40-21, Step 139/179 in Ep 14, 0.21s  train_loss:9.6843\n",
      "2020-06-26_07-40-25, Step 159/179 in Ep 14, 0.21s  train_loss:9.5404\n",
      "2020-06-26_07-40-29, Step 178/179 in Ep 14, 0.05s  train_loss:26.3231\n",
      "Epoch 14, LR 0.010000000000000002, Train_Time 38.01s, Loss: 11.1040\n",
      "Evaluation on test set, \n",
      " ma: 0.8187,  pos_recall: 0.6675 , neg_recall: 0.9699 \n",
      " Acc: 0.7972, Prec: 0.8730, Rec: 0.8726, F1: 0.8714\n",
      "2020-06-26_07-40-37\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-40-43, Step 19/179 in Ep 15, 0.21s  train_loss:10.0659\n",
      "2020-06-26_07-40-48, Step 39/179 in Ep 15, 0.21s  train_loss:8.8598\n",
      "2020-06-26_07-40-52, Step 59/179 in Ep 15, 0.21s  train_loss:12.1309\n",
      "2020-06-26_07-40-56, Step 79/179 in Ep 15, 0.21s  train_loss:12.2098\n",
      "2020-06-26_07-41-00, Step 99/179 in Ep 15, 0.21s  train_loss:9.1893\n",
      "2020-06-26_07-41-04, Step 119/179 in Ep 15, 0.21s  train_loss:8.6420\n",
      "2020-06-26_07-41-08, Step 139/179 in Ep 15, 0.21s  train_loss:9.5132\n",
      "2020-06-26_07-41-13, Step 159/179 in Ep 15, 0.21s  train_loss:8.5323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-26_07-41-16, Step 178/179 in Ep 15, 0.06s  train_loss:23.5943\n",
      "Epoch 15, LR 0.010000000000000002, Train_Time 37.88s, Loss: 9.6337\n",
      "Evaluation on test set, \n",
      " ma: 0.8127,  pos_recall: 0.6551 , neg_recall: 0.9703 \n",
      " Acc: 0.7989, Prec: 0.8755, Rec: 0.8725, F1: 0.8726\n",
      "2020-06-26_07-41-24\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-41-31, Step 19/179 in Ep 16, 0.21s  train_loss:10.3967\n",
      "2020-06-26_07-41-35, Step 39/179 in Ep 16, 0.21s  train_loss:8.9182\n",
      "2020-06-26_07-41-39, Step 59/179 in Ep 16, 0.21s  train_loss:8.9864\n",
      "2020-06-26_07-41-43, Step 79/179 in Ep 16, 0.21s  train_loss:9.0063\n",
      "2020-06-26_07-41-48, Step 99/179 in Ep 16, 0.21s  train_loss:9.2741\n",
      "2020-06-26_07-41-52, Step 119/179 in Ep 16, 0.21s  train_loss:9.6947\n",
      "2020-06-26_07-41-56, Step 139/179 in Ep 16, 0.21s  train_loss:9.6399\n",
      "2020-06-26_07-42-00, Step 159/179 in Ep 16, 0.21s  train_loss:7.5959\n",
      "2020-06-26_07-42-04, Step 178/179 in Ep 16, 0.07s  train_loss:33.1007\n",
      "Epoch 16, LR 0.010000000000000002, Train_Time 38.07s, Loss: 9.0958\n",
      "Evaluation on test set, \n",
      " ma: 0.8115,  pos_recall: 0.6530 , neg_recall: 0.9700 \n",
      " Acc: 0.8004, Prec: 0.8754, Rec: 0.8747, F1: 0.8736\n",
      "2020-06-26_07-42-12\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-42-19, Step 19/179 in Ep 17, 0.21s  train_loss:7.8655\n",
      "2020-06-26_07-42-23, Step 39/179 in Ep 17, 0.21s  train_loss:7.8447\n",
      "2020-06-26_07-42-27, Step 59/179 in Ep 17, 0.21s  train_loss:6.5921\n",
      "2020-06-26_07-42-31, Step 79/179 in Ep 17, 0.22s  train_loss:8.3966\n",
      "2020-06-26_07-42-36, Step 99/179 in Ep 17, 0.21s  train_loss:8.5909\n",
      "2020-06-26_07-42-40, Step 119/179 in Ep 17, 0.21s  train_loss:8.5297\n",
      "2020-06-26_07-42-44, Step 139/179 in Ep 17, 0.21s  train_loss:8.7666\n",
      "2020-06-26_07-42-48, Step 159/179 in Ep 17, 0.21s  train_loss:8.7459\n",
      "2020-06-26_07-42-52, Step 178/179 in Ep 17, 0.06s  train_loss:15.3926\n",
      "Epoch 17, LR 0.010000000000000002, Train_Time 38.11s, Loss: 8.5078\n",
      "Evaluation on test set, \n",
      " ma: 0.8105,  pos_recall: 0.6503 , neg_recall: 0.9706 \n",
      " Acc: 0.8005, Prec: 0.8760, Rec: 0.8737, F1: 0.8735\n",
      "2020-06-26_07-43-00\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-43-05, Step 19/179 in Ep 18, 0.21s  train_loss:6.5620\n",
      "2020-06-26_07-43-09, Step 39/179 in Ep 18, 0.21s  train_loss:6.6766\n",
      "2020-06-26_07-43-13, Step 59/179 in Ep 18, 0.21s  train_loss:9.8528\n",
      "2020-06-26_07-43-17, Step 79/179 in Ep 18, 0.21s  train_loss:8.6578\n",
      "2020-06-26_07-43-21, Step 99/179 in Ep 18, 0.21s  train_loss:7.8629\n",
      "2020-06-26_07-43-26, Step 119/179 in Ep 18, 0.21s  train_loss:7.3834\n",
      "2020-06-26_07-43-30, Step 139/179 in Ep 18, 0.21s  train_loss:9.4103\n",
      "2020-06-26_07-43-34, Step 159/179 in Ep 18, 0.21s  train_loss:6.8816\n",
      "2020-06-26_07-43-38, Step 178/179 in Ep 18, 0.06s  train_loss:18.9815\n",
      "Epoch 18, LR 0.010000000000000002, Train_Time 37.82s, Loss: 8.1769\n",
      "Evaluation on test set, \n",
      " ma: 0.8144,  pos_recall: 0.6584 , neg_recall: 0.9705 \n",
      " Acc: 0.7975, Prec: 0.8737, Rec: 0.8716, F1: 0.8712\n",
      "2020-06-26_07-43-47\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-43-52, Step 19/179 in Ep 19, 0.21s  train_loss:7.7153\n",
      "2020-06-26_07-43-56, Step 39/179 in Ep 19, 0.21s  train_loss:8.5266\n",
      "2020-06-26_07-44-00, Step 59/179 in Ep 19, 0.21s  train_loss:6.5747\n",
      "2020-06-26_07-44-04, Step 79/179 in Ep 19, 0.21s  train_loss:8.7052\n",
      "2020-06-26_07-44-09, Step 99/179 in Ep 19, 0.21s  train_loss:8.4719\n",
      "2020-06-26_07-44-13, Step 119/179 in Ep 19, 0.21s  train_loss:6.2819\n",
      "2020-06-26_07-44-17, Step 139/179 in Ep 19, 0.21s  train_loss:8.7052\n",
      "2020-06-26_07-44-21, Step 159/179 in Ep 19, 0.21s  train_loss:5.7944\n",
      "2020-06-26_07-44-25, Step 178/179 in Ep 19, 0.06s  train_loss:13.1075\n",
      "Epoch 19, LR 0.010000000000000002, Train_Time 37.99s, Loss: 7.8473\n",
      "Evaluation on test set, \n",
      " ma: 0.8119,  pos_recall: 0.6535 , neg_recall: 0.9703 \n",
      " Acc: 0.8003, Prec: 0.8765, Rec: 0.8731, F1: 0.8734\n",
      "2020-06-26_07-44-33\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-44-38, Step 19/179 in Ep 20, 0.21s  train_loss:8.4290\n",
      "2020-06-26_07-44-42, Step 39/179 in Ep 20, 0.21s  train_loss:6.8004\n",
      "2020-06-26_07-44-46, Step 59/179 in Ep 20, 0.21s  train_loss:5.5222\n",
      "2020-06-26_07-44-50, Step 79/179 in Ep 20, 0.21s  train_loss:9.1695\n",
      "2020-06-26_07-44-54, Step 99/179 in Ep 20, 0.21s  train_loss:7.9518\n",
      "2020-06-26_07-44-59, Step 119/179 in Ep 20, 0.21s  train_loss:6.3399\n",
      "2020-06-26_07-45-03, Step 139/179 in Ep 20, 0.21s  train_loss:10.2885\n",
      "2020-06-26_07-45-07, Step 159/179 in Ep 20, 0.21s  train_loss:7.1083\n",
      "2020-06-26_07-45-11, Step 178/179 in Ep 20, 0.06s  train_loss:15.6934\n",
      "Epoch 20, LR 0.0010000000000000002, Train_Time 38.01s, Loss: 7.4301\n",
      "Evaluation on test set, \n",
      " ma: 0.8140,  pos_recall: 0.6577 , neg_recall: 0.9704 \n",
      " Acc: 0.8017, Prec: 0.8766, Rec: 0.8747, F1: 0.8743\n",
      "2020-06-26_07-45-20\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-45-26, Step 19/179 in Ep 21, 0.21s  train_loss:6.9465\n",
      "2020-06-26_07-45-31, Step 39/179 in Ep 21, 0.21s  train_loss:5.5335\n",
      "2020-06-26_07-45-35, Step 59/179 in Ep 21, 0.21s  train_loss:6.4888\n",
      "2020-06-26_07-45-39, Step 79/179 in Ep 21, 0.21s  train_loss:6.8523\n",
      "2020-06-26_07-45-43, Step 99/179 in Ep 21, 0.21s  train_loss:7.3574\n",
      "2020-06-26_07-45-47, Step 119/179 in Ep 21, 0.21s  train_loss:5.0836\n",
      "2020-06-26_07-45-52, Step 139/179 in Ep 21, 0.21s  train_loss:7.4545\n",
      "2020-06-26_07-45-56, Step 159/179 in Ep 21, 0.21s  train_loss:6.9542\n",
      "2020-06-26_07-46-00, Step 178/179 in Ep 21, 0.06s  train_loss:23.6046\n",
      "Epoch 21, LR 0.0010000000000000002, Train_Time 37.96s, Loss: 7.3087\n",
      "Evaluation on test set, \n",
      " ma: 0.8139,  pos_recall: 0.6576 , neg_recall: 0.9702 \n",
      " Acc: 0.8003, Prec: 0.8754, Rec: 0.8742, F1: 0.8734\n",
      "2020-06-26_07-46-07\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-46-12, Step 19/179 in Ep 22, 0.21s  train_loss:8.2144\n",
      "2020-06-26_07-46-16, Step 39/179 in Ep 22, 0.21s  train_loss:5.4752\n",
      "2020-06-26_07-46-20, Step 59/179 in Ep 22, 0.21s  train_loss:6.3513\n",
      "2020-06-26_07-46-25, Step 79/179 in Ep 22, 0.21s  train_loss:7.7801\n",
      "2020-06-26_07-46-29, Step 99/179 in Ep 22, 0.21s  train_loss:5.9693\n",
      "2020-06-26_07-46-33, Step 119/179 in Ep 22, 0.21s  train_loss:6.5862\n",
      "2020-06-26_07-46-37, Step 139/179 in Ep 22, 0.21s  train_loss:7.1887\n",
      "2020-06-26_07-46-41, Step 159/179 in Ep 22, 0.21s  train_loss:7.3938\n",
      "2020-06-26_07-46-45, Step 178/179 in Ep 22, 0.06s  train_loss:22.0286\n",
      "Epoch 22, LR 0.0010000000000000002, Train_Time 37.98s, Loss: 7.2598\n",
      "Evaluation on test set, \n",
      " ma: 0.8162,  pos_recall: 0.6625 , neg_recall: 0.9699 \n",
      " Acc: 0.8012, Prec: 0.8751, Rec: 0.8757, F1: 0.8740\n",
      "2020-06-26_07-46-54\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-46-59, Step 19/179 in Ep 23, 0.21s  train_loss:6.4074\n",
      "2020-06-26_07-47-03, Step 39/179 in Ep 23, 0.21s  train_loss:5.7650\n",
      "2020-06-26_07-47-07, Step 59/179 in Ep 23, 0.21s  train_loss:6.4736\n",
      "2020-06-26_07-47-11, Step 79/179 in Ep 23, 0.22s  train_loss:8.1280\n",
      "2020-06-26_07-47-16, Step 99/179 in Ep 23, 0.21s  train_loss:7.2020\n",
      "2020-06-26_07-47-20, Step 119/179 in Ep 23, 0.21s  train_loss:6.4266\n",
      "2020-06-26_07-47-24, Step 139/179 in Ep 23, 0.21s  train_loss:8.4886\n",
      "2020-06-26_07-47-28, Step 159/179 in Ep 23, 0.21s  train_loss:5.8029\n",
      "2020-06-26_07-47-32, Step 178/179 in Ep 23, 0.06s  train_loss:23.9670\n",
      "Epoch 23, LR 0.0010000000000000002, Train_Time 38.29s, Loss: 7.2521\n",
      "Evaluation on test set, \n",
      " ma: 0.8159,  pos_recall: 0.6608 , neg_recall: 0.9710 \n",
      " Acc: 0.8010, Prec: 0.8773, Rec: 0.8731, F1: 0.8738\n",
      "2020-06-26_07-47-40\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-47-45, Step 19/179 in Ep 24, 0.21s  train_loss:7.0239\n",
      "2020-06-26_07-47-49, Step 39/179 in Ep 24, 0.21s  train_loss:6.6641\n",
      "2020-06-26_07-47-53, Step 59/179 in Ep 24, 0.21s  train_loss:7.1437\n",
      "2020-06-26_07-47-57, Step 79/179 in Ep 24, 0.21s  train_loss:7.1902\n",
      "2020-06-26_07-48-01, Step 99/179 in Ep 24, 0.21s  train_loss:6.4709\n",
      "2020-06-26_07-48-06, Step 119/179 in Ep 24, 0.21s  train_loss:5.6580\n",
      "2020-06-26_07-48-10, Step 139/179 in Ep 24, 0.22s  train_loss:7.6608\n",
      "2020-06-26_07-48-14, Step 159/179 in Ep 24, 0.21s  train_loss:7.2423\n",
      "2020-06-26_07-48-18, Step 178/179 in Ep 24, 0.06s  train_loss:18.1605\n",
      "Epoch 24, LR 0.0010000000000000002, Train_Time 38.18s, Loss: 7.1462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation on test set, \n",
      " ma: 0.8121,  pos_recall: 0.6543 , neg_recall: 0.9700 \n",
      " Acc: 0.8020, Prec: 0.8764, Rec: 0.8756, F1: 0.8746\n",
      "2020-06-26_07-48-26\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-48-32, Step 19/179 in Ep 25, 0.21s  train_loss:7.8659\n",
      "2020-06-26_07-48-37, Step 39/179 in Ep 25, 0.21s  train_loss:6.4931\n",
      "2020-06-26_07-48-41, Step 59/179 in Ep 25, 0.21s  train_loss:6.1461\n",
      "2020-06-26_07-48-45, Step 79/179 in Ep 25, 0.21s  train_loss:8.1687\n",
      "2020-06-26_07-48-49, Step 99/179 in Ep 25, 0.21s  train_loss:6.7704\n",
      "2020-06-26_07-48-53, Step 119/179 in Ep 25, 0.21s  train_loss:6.8386\n",
      "2020-06-26_07-48-58, Step 139/179 in Ep 25, 0.22s  train_loss:8.4029\n",
      "2020-06-26_07-49-02, Step 159/179 in Ep 25, 0.21s  train_loss:6.5708\n",
      "2020-06-26_07-49-06, Step 178/179 in Ep 25, 0.06s  train_loss:35.5921\n",
      "Epoch 25, LR 0.00010000000000000003, Train_Time 38.25s, Loss: 7.1847\n",
      "Evaluation on test set, \n",
      " ma: 0.8130,  pos_recall: 0.6558 , neg_recall: 0.9702 \n",
      " Acc: 0.8005, Prec: 0.8752, Rec: 0.8745, F1: 0.8735\n",
      "2020-06-26_07-49-14\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-49-18, Step 19/179 in Ep 26, 0.21s  train_loss:6.8255\n",
      "2020-06-26_07-49-23, Step 39/179 in Ep 26, 0.21s  train_loss:6.8357\n",
      "2020-06-26_07-49-27, Step 59/179 in Ep 26, 0.21s  train_loss:5.7645\n",
      "2020-06-26_07-49-31, Step 79/179 in Ep 26, 0.21s  train_loss:7.5008\n",
      "2020-06-26_07-49-35, Step 99/179 in Ep 26, 0.21s  train_loss:6.0529\n",
      "2020-06-26_07-49-39, Step 119/179 in Ep 26, 0.22s  train_loss:6.8574\n",
      "2020-06-26_07-49-44, Step 139/179 in Ep 26, 0.21s  train_loss:8.8293\n",
      "2020-06-26_07-49-48, Step 159/179 in Ep 26, 0.21s  train_loss:8.3272\n",
      "2020-06-26_07-49-52, Step 178/179 in Ep 26, 0.06s  train_loss:18.8424\n",
      "Epoch 26, LR 0.00010000000000000003, Train_Time 38.12s, Loss: 7.1086\n",
      "Evaluation on test set, \n",
      " ma: 0.8161,  pos_recall: 0.6620 , neg_recall: 0.9701 \n",
      " Acc: 0.8014, Prec: 0.8760, Rec: 0.8753, F1: 0.8743\n",
      "2020-06-26_07-50-00\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-50-04, Step 19/179 in Ep 27, 0.21s  train_loss:5.3409\n",
      "2020-06-26_07-50-08, Step 39/179 in Ep 27, 0.21s  train_loss:6.5600\n",
      "2020-06-26_07-50-13, Step 59/179 in Ep 27, 0.21s  train_loss:7.2606\n",
      "2020-06-26_07-50-17, Step 79/179 in Ep 27, 0.21s  train_loss:8.4842\n",
      "2020-06-26_07-50-21, Step 99/179 in Ep 27, 0.21s  train_loss:5.3539\n",
      "2020-06-26_07-50-25, Step 119/179 in Ep 27, 0.21s  train_loss:5.7185\n",
      "2020-06-26_07-50-29, Step 139/179 in Ep 27, 0.21s  train_loss:7.7880\n",
      "2020-06-26_07-50-34, Step 159/179 in Ep 27, 0.21s  train_loss:7.0634\n",
      "2020-06-26_07-50-38, Step 178/179 in Ep 27, 0.06s  train_loss:15.5892\n",
      "Epoch 27, LR 0.00010000000000000003, Train_Time 38.02s, Loss: 7.0732\n",
      "Evaluation on test set, \n",
      " ma: 0.8152,  pos_recall: 0.6606 , neg_recall: 0.9698 \n",
      " Acc: 0.8008, Prec: 0.8749, Rec: 0.8755, F1: 0.8738\n",
      "2020-06-26_07-50-46\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-50-50, Step 19/179 in Ep 28, 0.21s  train_loss:8.2164\n",
      "2020-06-26_07-50-56, Step 39/179 in Ep 28, 0.21s  train_loss:5.7596\n",
      "2020-06-26_07-51-06, Step 59/179 in Ep 28, 0.22s  train_loss:7.5189\n",
      "2020-06-26_07-51-10, Step 79/179 in Ep 28, 0.21s  train_loss:6.9511\n",
      "2020-06-26_07-51-15, Step 99/179 in Ep 28, 0.21s  train_loss:7.3758\n",
      "2020-06-26_07-51-19, Step 119/179 in Ep 28, 0.22s  train_loss:5.9836\n",
      "2020-06-26_07-51-23, Step 139/179 in Ep 28, 0.21s  train_loss:7.5159\n",
      "2020-06-26_07-51-27, Step 159/179 in Ep 28, 0.21s  train_loss:6.3122\n",
      "2020-06-26_07-51-31, Step 178/179 in Ep 28, 0.06s  train_loss:22.2003\n",
      "Epoch 28, LR 0.00010000000000000003, Train_Time 45.89s, Loss: 7.1235\n",
      "Evaluation on test set, \n",
      " ma: 0.8167,  pos_recall: 0.6630 , neg_recall: 0.9704 \n",
      " Acc: 0.8010, Prec: 0.8751, Rec: 0.8755, F1: 0.8739\n",
      "2020-06-26_07-51-40\n",
      "------------------------------------------------------------\n",
      "2020-06-26_07-51-44, Step 19/179 in Ep 29, 0.21s  train_loss:5.5230\n",
      "2020-06-26_07-51-49, Step 39/179 in Ep 29, 0.21s  train_loss:5.5898\n",
      "2020-06-26_07-51-53, Step 59/179 in Ep 29, 0.21s  train_loss:6.6376\n",
      "2020-06-26_07-51-57, Step 79/179 in Ep 29, 0.21s  train_loss:7.3382\n",
      "2020-06-26_07-52-01, Step 99/179 in Ep 29, 0.22s  train_loss:7.2719\n",
      "2020-06-26_07-52-06, Step 119/179 in Ep 29, 0.22s  train_loss:6.0342\n",
      "2020-06-26_07-52-10, Step 139/179 in Ep 29, 0.22s  train_loss:7.0264\n",
      "2020-06-26_07-52-14, Step 159/179 in Ep 29, 0.21s  train_loss:6.4042\n",
      "2020-06-26_07-52-26, Step 178/179 in Ep 29, 0.05s  train_loss:14.9377\n",
      "Epoch 29, LR 0.00010000000000000003, Train_Time 46.25s, Loss: 7.0642\n",
      "Evaluation on test set, \n",
      " ma: 0.8132,  pos_recall: 0.6559 , neg_recall: 0.9704 \n",
      " Acc: 0.8011, Prec: 0.8767, Rec: 0.8742, F1: 0.8740\n",
      "2020-06-26_07-52-34\n",
      "------------------------------------------------------------\n",
      "PETA,  best_metrc : 0.8746373970664213 in epoch24\n"
     ]
    }
   ],
   "source": [
    "visenv_name = args.dataset\n",
    "exp_dir = os.path.join('exp_result', args.dataset)\n",
    "model_dir, log_dir = get_model_log_path(exp_dir, visenv_name)\n",
    "\n",
    "# Added for logging purposes\n",
    "user = getpass.getuser() \n",
    "fixed_time_str = time_str()\n",
    "stdout_file = os.path.join(log_dir, \"_\".join(['stdout', user, f'{fixed_time_str}.txt']) )\n",
    "save_model_path = os.path.join(model_dir,  \"_\".join(['ckpt_max', user, f'{fixed_time_str}.pth']) )\n",
    "trackitems_dir = os.path.join(log_dir, \"_\".join(['trackitems', user, f'{fixed_time_str}.txt']) )\n",
    "\n",
    "\n",
    "if args.redirector:\n",
    "    print('redirector stdout')\n",
    "    ReDirectSTD(stdout_file, 'stdout', False)\n",
    "\n",
    "pprint.pprint(OrderedDict(args.__dict__))\n",
    "\n",
    "print('-' * 60)\n",
    "print(f'use GPU{args.device} for training')\n",
    "print(f'train set: {args.dataset} {args.train_split}, test set: {args.valid_split}')\n",
    "\n",
    "#train_tsfm, valid_tsfm = get_transform(args)\n",
    "#print(train_tsfm)\n",
    "\n",
    "# This is changed\n",
    "train_set = AttrDataset_new(args=args, split=args.train_split, transformation_dict=args.train_transform)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    dataset=train_set,\n",
    "    batch_size=args.batchsize,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# This is changed\n",
    "valid_set = AttrDataset_new(args=args, split=args.valid_split, transformation_dict=args.valid_transform)\n",
    "\n",
    "valid_loader = DataLoader(\n",
    "    dataset=valid_set,\n",
    "    batch_size=args.batchsize,\n",
    "    shuffle=False,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "print(f'{args.train_split} set: {len(train_loader.dataset)}, '\n",
    "      f'{args.valid_split} set: {len(valid_loader.dataset)}, '\n",
    "      f'attr_num : {train_set.attr_num}')\n",
    "\n",
    "labels = train_set.label\n",
    "sample_weight = labels.mean(0)\n",
    "\n",
    "backbone = resnet50()\n",
    "classifier = BaseClassifier(nattr=train_set.attr_num)\n",
    "model = FeatClassifier(backbone, classifier)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "criterion = CEL_Sigmoid(sample_weight)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    param_groups = [{'params': model.module.finetune_params(), 'lr': args.lr_ft},\n",
    "                    {'params': model.module.fresh_params(), 'lr': args.lr_new}]\n",
    "else:\n",
    "    param_groups = [{'params': model.finetune_params(), 'lr': args.lr_ft},\n",
    "                    {'params': model.fresh_params(), 'lr': args.lr_new}]\n",
    "optimizer = torch.optim.SGD(param_groups, momentum=args.momentum, weight_decay=args.weight_decay, nesterov=False)\n",
    "lr_scheduler = ReduceLROnPlateau(optimizer, factor=0.1, patience=4)\n",
    "\n",
    "# Added for logging purposes\n",
    "with open(trackitems_dir, \"a\") as f:\n",
    "    code, line_no = inspect.getsourcelines(get_transform)\n",
    "    for line in code:\n",
    "        f.write(str(line))\n",
    "    f.write(str(\"\\n\\n\"))\n",
    "\n",
    "    f.write(str(args.__dict__))\n",
    "    f.write(str(\"\\n\\n\"))\n",
    "\n",
    "    f.write(str(lr_scheduler.__dict__))\n",
    "    f.write(str(\"\\n\\n\"))\n",
    "\n",
    "    model_str = str(model).lower()\n",
    "    have_dropout = 'dropout' in model_str\n",
    "    f.write('dropout: %s' %(have_dropout))\n",
    "    f.write(str(\"\\n\\n\"))\n",
    "\n",
    "    have_leaky_relu = 'leaky_relu' in model_str\n",
    "    f.write('leaky_relu: %s' %(have_leaky_relu))\n",
    "    f.write(str(\"\\n\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:12<00:00,  9.82it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.35it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 14.96it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.40it/s]\n",
      "100%|██████████| 119/119 [00:08<00:00, 14.45it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.78it/s]\n",
      "100%|██████████| 119/119 [00:08<00:00, 14.55it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.40it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 14.95it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.24it/s]\n",
      "100%|██████████| 119/119 [00:08<00:00, 14.76it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.46it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.48it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.26it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.21it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.10it/s]\n",
      "100%|██████████| 119/119 [00:08<00:00, 14.72it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.17it/s]\n",
      "100%|██████████| 119/119 [00:09<00:00, 12.94it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.38it/s]\n",
      "100%|██████████| 119/119 [00:08<00:00, 13.38it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.64it/s]\n",
      "100%|██████████| 119/119 [00:08<00:00, 13.87it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.55it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.26it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.49it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.23it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.04it/s]\n",
      "100%|██████████| 119/119 [00:08<00:00, 14.62it/s]\n",
      "100%|██████████| 119/119 [00:07<00:00, 15.04it/s]\n"
     ]
    }
   ],
   "source": [
    "best_metric, epoch = trainer(epoch=args.train_epoch,\n",
    "                             model=model,\n",
    "                             train_loader=train_loader,\n",
    "                             valid_loader=valid_loader,\n",
    "                             criterion=criterion,\n",
    "                             optimizer=optimizer,\n",
    "                             lr_scheduler=lr_scheduler,\n",
    "                             path=save_model_path,\n",
    "                             measure='f1')\n",
    "\n",
    "print(f'{visenv_name},  best_metrc : {best_metric} in epoch{epoch}')\n",
    "\n",
    "# Added for logging purposes\n",
    "with open(trackitems_dir, \"a\") as f:\n",
    "    f.write(f'{visenv_name},  best_metrc : {best_metric} in epoch{epoch}')\n",
    "    f.write(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
